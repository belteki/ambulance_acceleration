{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./Cerny_logo_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cerny ventilation recordings\n",
    "\n",
    "The data processed and analysed in this Notebook were collected by the **Neonatal Emergency and Transport Service of the Peter Cerny Foundation**, Budapest, Hungary\n",
    "\n",
    "**Author: Dr Gusztav Belteki**\n",
    "\n",
    "\n",
    "## Further processing and analysis of ventilator parameters \n",
    "\n",
    "This notebook import the preprocessed ventilator data from pickle archive and analyses all the ventilator parameter data and alarms data obtained with **0.5Hz sampling rate** from the Fabian ventilators at the Cerny neonatal transport service. It exports desrciptive statistics into Excel files and the further processed data as pickle archive.\n",
    "\n",
    "Imported: **data_pars_1_150.pickle**, **data_pars_151_300.pickle**, **Fabian_parameters.xlsx**  \n",
    "\n",
    "- Total: **246 cases** with ventilator data available (with >15 minutes recording time)\n",
    "- Clinical data were not available for **4 cases** \n",
    "- Appropriate ventilator and clinical data are available for **242 cases**\n",
    "\n",
    "Exported: dictionaries containing ventilation data as **data_pars_measurements_1_300.pickle,  data_pars_settings_1_300.pickle, data_pars_alarms_1_300.pickle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries and setting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('classic')\n",
    "matplotlib.rcParams['figure.facecolor'] = 'w'\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# pd.set_option('mode.chained_assignment', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))\n",
    "print(\"scikit-learn version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and set the working directory and the directory to write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic of the Notebook which will also be the name of the subfolder containing results\n",
    "TOPIC = 'fabian'\n",
    "\n",
    "# Name of the external hard drive\n",
    "DRIVE = 'GUSZTI'\n",
    "\n",
    "# Directory containing clinical and blood gas data\n",
    "CWD = '/Users/guszti/ventilation_fabian'\n",
    "\n",
    "DIR_WRITE = '%s/%s/%s' % (CWD, 'Analyses', 'analysis_1_300')\n",
    "if not os.path.isdir(DIR_WRITE):\n",
    "    os.makedirs(DIR_WRITE)\n",
    "\n",
    "# Images and raw data will be written on an external hard drive\n",
    "if not os.path.isdir('/Volumes/%s/data_dump/%s' % (DRIVE, TOPIC)):\n",
    "    os.makedirs('/Volumes/%s/data_dump/%s' % (DRIVE, TOPIC))\n",
    "DATA_DUMP = '/Volumes/%s/data_dump/%s' % (DRIVE, TOPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CWD)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WRITE, DATA_DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pickle archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventilator data\n",
    "\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'data_pars_1_150'), 'rb') as handle:\n",
    "    data_pars_1_150 = pickle.load(handle)\n",
    "\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'data_pars_151_300'), 'rb') as handle:\n",
    "    data_pars_151_300 = pickle.load(handle)\n",
    "    \n",
    "data_pars = {**data_pars_1_150, **data_pars_151_300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical data\n",
    "\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'clin_df_1_300'), 'rb') as handle:\n",
    "    clin_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit ventilator data to cases for which clinical data and appropriate (>15 minutes) ventilator data are available\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = sorted(set(list(clin_df.index)) & set(data_pars.keys()))\n",
    "data_pars = {key : value for key, value in data_pars.items() if key in combined}\n",
    "cases = sorted(data_pars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import table for interpreting ventilator parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_key_table = pd.read_excel('Fabian_parameters.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_key_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of Dataframes with measured ventilator parameters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_measurements = ['PIP', 'MAP', 'PEEP', 'Ti_PSV', 'Cdyn', 'C20_C', 'R', 'MV', 'MVresp',\n",
    " 'VTemand', 'VTemand_resp', 'VTespon_pat', 'Leak', 'RR', 'Trigger', 'VTimand', 'FiO2',\n",
    " 'Flow_demand', 'Flow_insp', 'Flow_exp',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pars_measurements = {}\n",
    "\n",
    "for case in cases:\n",
    "    data_pars_measurements[case] = data_pars[case][ventilator_measurements].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace textual data with np.nan\n",
    "repl_dct = {'off': np.nan, 'not valid': np.nan, 'out of range': np.nan, 'unused': np.nan}\n",
    "for case in cases:\n",
    "    data_pars_measurements[case].replace(repl_dct, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize relevant parameters to body weight\n",
    "pars_per_kg = ['MV', 'VTimand', 'VTemand', 'VTespon_pat', 'VTemand_resp']\n",
    "\n",
    "for case in cases:\n",
    "    for par in pars_per_kg:\n",
    "        data_pars_measurements[case]['%s_kg' % par] = \\\n",
    "        data_pars_measurements[case][par] / (clin_df.loc[case]['Weight'] / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which only have NaN values\n",
    "for case in cases:\n",
    "    data_pars_measurements[case].dropna(axis = 1, how = 'all', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dictionary containing measured ventilator parameters to a pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'data_pars_measurements_1_300'), 'wb') as handle:\n",
    "    pickle.dump(data_pars_measurements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of Dataframes with ventilator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_settings = ['Patient_range', 'Ventilator_mode', 'PIP_set', 'PEEP_set', 'PIP_set_PSV', \n",
    "'FiO2_set', 'Flow_insp_set','Slope_set', 'Flow_exp_set', 'Ti_set', 'Te_set', 'RR_set', \n",
    "'IE_I_set', 'IE_E_set', 'Volume_limit_set', 'VG_set', 'Term_criteria_PSV_set', 'Apnea_time_set', \n",
    "'RR_backup_set', 'Trigger_sens_set', 'Powerstate', 'MV_lim_high_set',\n",
    "'MV_lim_low_set', 'PIP_lim_high_set', 'PIP_lim_low_set', 'RR_lim_set', 'Leakage_lim_set',\n",
    "'Measuring_unit_pressure_set', 'Flow_sensor_state', 'Oxy_sensor_state',\n",
    "'P_man_breath_CPAP_HFO_set', 'P_man_breath_duoPAP_NCPAP_set', 'FiO2_flush_time_set', 'FiO2_flush_set',\n",
    "'Ventilation_stopped', 'VG_state', 'Volume_limit_state', 'Ventilator_range', 'Trigger_mode',\n",
    "'Pressure_rise_control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pars_settings = {}\n",
    "\n",
    "for case in cases:\n",
    "    data_pars_settings[case] = data_pars[case][ventilator_settings].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace textual data with np.nan\n",
    "repl_dct = {'off': np.nan, 'not valid': np.nan, 'out of range': np.nan, 'unused': np.nan}\n",
    "for case in cases:\n",
    "    data_pars_settings[case].replace(repl_dct, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize relevant parameters to body weight\n",
    "pars_per_kg = ['Volume_limit_set', 'VG_set', 'MV_lim_high_set', 'MV_lim_low_set',]\n",
    "\n",
    "for case in cases:\n",
    "    for par in pars_per_kg:\n",
    "        data_pars_settings[case]['%s_kg' % par] = \\\n",
    "        data_pars_settings[case][par] / (clin_df.loc[case]['Weight'] / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which only have NaN values\n",
    "for case in cases:\n",
    "    data_pars_settings[case].dropna(axis=1, how='all', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dictionary containing ventilator settings to a pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'data_pars_settings_1_300'), 'wb') as handle:\n",
    "    pickle.dump(data_pars_settings, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of Dataframes with ventilator alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_alarms = ['Alarm_susp', 'Alarm_Flat_battery', 'Alarm_Checksum_ctrl_PIC', 'Alarm_Checksum_monitor_PIC',\n",
    "'Alarm_Safety_relay_defect', 'Alarm_Sens_dev_prox_pressure', 'Alarm_input_pressure_blender', 'Alarm_excess_pressure',\n",
    "'Alarm_voltage_monit', 'Alarm_SPI_interface', 'Alarm_DIO2_interface', 'Alarm_COM_interface', 'Alarm_I2C_interface',\n",
    "'Alarm_parallel_interface', 'Alarm_serial_tem_interface', 'Alarm_low_physical_memory', 'Alarm_Fan_defect',\n",
    "'Alarm_CO2_interface', 'Alarm_blender_defect', 'Alarm_battery_defect', 'Alarm_input_pressure_O2_supply',\n",
    "'Alarm_input_pressure_air_supply', 'Alarm_tube_occlusion', 'Alarm_patient_disconnected', 'Alarm_ETT_blocked',\n",
    "'Alarm_flow_sensor_defect', 'Alarm_flow_sensor_clean', 'Alarm_flow_sensor_disconnected', 'Oxygen_sensor_defect',\n",
    "'Oxygen_sensor_used_up', 'Oxyen_value_divergence', 'Alarm_O2_sensor_cal_error', 'Alarm_MV_high', 'Alarm_MV_low',\n",
    "'Alarm_pressure_high', 'Alarm_pressure_low', 'Alarm_PEEP_high', 'Alarm_RR_high', 'Alarm_ETT_leak_high','Alarm_apnea',\n",
    "'Alarm_DCO2_high', 'Alarm_DCO2_low', 'Alarm_etCO2_high','Alarm_etCO2_low', 'Alarm_PIP_not_reached',\n",
    "'Alarm_limited_volume', 'Alarm_volume_not_reached', 'Alarm_power_failure', 'Alarm_charge_battery_60min',\n",
    "'Alarm_charge_battery_30min', 'Alarm_charge_battery_15min', 'Alarm_nebulizer_disconnection',\n",
    "'Alarm_nebulizer_system_error', 'Alarm_CO2_module_not_connected', 'Alarm_CO2_filterline_not_connected',\n",
    "'Alarm_CO2_check_sampleline', 'Alarm_CO2_check_airway_adapter', 'Alarm_CO2_sensor_faulty',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pars_alarms = {}\n",
    "\n",
    "for case in cases:\n",
    "    data_pars_alarms[case] = data_pars[case][ventilator_alarms].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace textual data with np.nan\n",
    "repl_dct = {'off': np.nan, 'not valid': np.nan, 'out of range': np.nan, 'unused': np.nan}\n",
    "for case in cases:\n",
    "    data_pars_alarms[case].replace(repl_dct, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which only have NaN values (these alarms never went off)\n",
    "for case in cases:\n",
    "    for column in data_pars_alarms[case].columns:\n",
    "        if data_pars_alarms[case][column].sum() == 0:\n",
    "            del data_pars_alarms[case][column]     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# How many different kind of alarms went off during each case\n",
    "for case in cases:\n",
    "    print(case, ':   ' len(data_pars_alarms[case].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dictionary containing ventilator alarms to a pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'data_pars_alarms_1_300'), 'wb') as handle:\n",
    "    pickle.dump(data_pars_alarms, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
